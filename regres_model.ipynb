{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file I will make regres model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CNN_mod.csv')\n",
    "X = df.drop(['w_time', 'Unnamed: 0'], axis=1).copy()\n",
    "y = df['w_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For making decision I need to iterate all regressors from scikit-learn. So let's do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer, MissingIndicator\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.utils import all_estimators\n",
    "from sklearn.base import RegressorMixin\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    r2_score,\n",
    "    mean_squared_error,\n",
    ")\n",
    "import warnings\n",
    "import xgboost\n",
    "\n",
    "# import catboost\n",
    "import lightgbm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.2f\" % x)\n",
    "\n",
    "\n",
    "\n",
    "removed_regressors = [\n",
    "    \"TheilSenRegressor\",\n",
    "    \"ARDRegression\", \n",
    "    \"CCA\", \n",
    "    \"IsotonicRegression\", \n",
    "    \"StackingRegressor\",\n",
    "    \"MultiOutputRegressor\", \n",
    "    \"MultiTaskElasticNet\", \n",
    "    \"MultiTaskElasticNetCV\", \n",
    "    \"MultiTaskLasso\", \n",
    "    \"MultiTaskLassoCV\", \n",
    "    \"PLSCanonical\", \n",
    "    \"PLSRegression\", \n",
    "    \"RadiusNeighborsRegressor\", \n",
    "    \"RegressorChain\", \n",
    "    \"VotingRegressor\", \n",
    "]\n",
    "\n",
    "CLASSIFIERS = [\n",
    "    est\n",
    "    for est in all_estimators()\n",
    "    if (issubclass(est[1], ClassifierMixin) and (est[0] not in removed_classifiers))\n",
    "]\n",
    "\n",
    "REGRESSORS = [\n",
    "    est\n",
    "    for est in all_estimators()\n",
    "    if (issubclass(est[1], RegressorMixin) and (est[0] not in removed_regressors))\n",
    "]\n",
    "\n",
    "REGRESSORS.append((\"XGBRegressor\", xgboost.XGBRegressor))\n",
    "REGRESSORS.append((\"LGBMRegressor\", lightgbm.LGBMRegressor))\n",
    "# REGRESSORS.append(('CatBoostRegressor',catboost.CatBoostRegressor))\n",
    "\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_transformer_low = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "        (\"encoding\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer_high = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "        # 'OrdianlEncoder' Raise a ValueError when encounters an unknown value. Check https://github.com/scikit-learn/scikit-learn/pull/13423\n",
    "        (\"encoding\", OrdinalEncoder()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Helper function\n",
    "\n",
    "\n",
    "def get_card_split(df, cols, n=11):\n",
    "    \"\"\"\n",
    "    Splits categorical columns into 2 lists based on cardinality (i.e # of unique values)\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Pandas DataFrame\n",
    "        DataFrame from which the cardinality of the columns is calculated.\n",
    "    cols : list-like\n",
    "        Categorical columns to list\n",
    "    n : int, optional (default=11)\n",
    "        The value of 'n' will be used to split columns.\n",
    "    Returns\n",
    "    -------\n",
    "    card_low : list-like\n",
    "        Columns with cardinality < n\n",
    "    card_high : list-like\n",
    "        Columns with cardinality >= n\n",
    "    \"\"\"\n",
    "    cond = df[cols].nunique() > n\n",
    "    card_high = cols[cond]\n",
    "    card_low = cols[~cond]\n",
    "    return card_low, card_high\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LazyRegressor:\n",
    "    \"\"\"\n",
    "    This module helps in fitting regression models that are available in Scikit-learn\n",
    "    Parameters\n",
    "    ----------\n",
    "    verbose : int, optional (default=0)\n",
    "        For the liblinear and lbfgs solvers set verbose to any positive\n",
    "        number for verbosity.\n",
    "    ignore_warnings : bool, optional (default=True)\n",
    "        When set to True, the warning related to algorigms that are not able to run are ignored.\n",
    "    custom_metric : function, optional (default=None)\n",
    "        When function is provided, models are evaluated based on the custom evaluation metric provided.\n",
    "    prediction : bool, optional (default=False)\n",
    "        When set to True, the predictions of all the models models are returned as dataframe.\n",
    "    regressors : list, optional (default=\"all\")\n",
    "        When function is provided, trains the chosen regressor(s).\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from lazypredict.Supervised import LazyRegressor\n",
    "    >>> from sklearn import datasets\n",
    "    >>> from sklearn.utils import shuffle\n",
    "    >>> import numpy as np\n",
    "    >>> boston = datasets.load_boston()\n",
    "    >>> X, y = shuffle(boston.data, boston.target, random_state=13)\n",
    "    >>> X = X.astype(np.float32)\n",
    "    >>> offset = int(X.shape[0] * 0.9)\n",
    "    >>> X_train, y_train = X[:offset], y[:offset]\n",
    "    >>> X_test, y_test = X[offset:], y[offset:]\n",
    "    >>> reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)\n",
    "    >>> models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "    >>> model_dictionary = reg.provide_models(X_train, X_test, y_train, y_test)\n",
    "    >>> models\n",
    "    | Model                         | Adjusted R-Squared | R-Squared |  RMSE | Time Taken |\n",
    "    |:------------------------------|-------------------:|----------:|------:|-----------:|\n",
    "    | SVR                           |               0.83 |      0.88 |  2.62 |       0.01 |\n",
    "    | BaggingRegressor              |               0.83 |      0.88 |  2.63 |       0.03 |\n",
    "    | NuSVR                         |               0.82 |      0.86 |  2.76 |       0.03 |\n",
    "    | RandomForestRegressor         |               0.81 |      0.86 |  2.78 |       0.21 |\n",
    "    | XGBRegressor                  |               0.81 |      0.86 |  2.79 |       0.06 |\n",
    "    | GradientBoostingRegressor     |               0.81 |      0.86 |  2.84 |       0.11 |\n",
    "    | ExtraTreesRegressor           |               0.79 |      0.84 |  2.98 |       0.12 |\n",
    "    | AdaBoostRegressor             |               0.78 |      0.83 |  3.04 |       0.07 |\n",
    "    | HistGradientBoostingRegressor |               0.77 |      0.83 |  3.06 |       0.17 |\n",
    "    | PoissonRegressor              |               0.77 |      0.83 |  3.11 |       0.01 |\n",
    "    | LGBMRegressor                 |               0.77 |      0.83 |  3.11 |       0.07 |\n",
    "    | KNeighborsRegressor           |               0.77 |      0.83 |  3.12 |       0.01 |\n",
    "    | DecisionTreeRegressor         |               0.65 |      0.74 |  3.79 |       0.01 |\n",
    "    | MLPRegressor                  |               0.65 |      0.74 |  3.80 |       1.63 |\n",
    "    | HuberRegressor                |               0.64 |      0.74 |  3.84 |       0.01 |\n",
    "    | GammaRegressor                |               0.64 |      0.73 |  3.88 |       0.01 |\n",
    "    | LinearSVR                     |               0.62 |      0.72 |  3.96 |       0.01 |\n",
    "    | RidgeCV                       |               0.62 |      0.72 |  3.97 |       0.01 |\n",
    "    | BayesianRidge                 |               0.62 |      0.72 |  3.97 |       0.01 |\n",
    "    | Ridge                         |               0.62 |      0.72 |  3.97 |       0.01 |\n",
    "    | TransformedTargetRegressor    |               0.62 |      0.72 |  3.97 |       0.01 |\n",
    "    | LinearRegression              |               0.62 |      0.72 |  3.97 |       0.01 |\n",
    "    | ElasticNetCV                  |               0.62 |      0.72 |  3.98 |       0.04 |\n",
    "    | LassoCV                       |               0.62 |      0.72 |  3.98 |       0.06 |\n",
    "    | LassoLarsIC                   |               0.62 |      0.72 |  3.98 |       0.01 |\n",
    "    | LassoLarsCV                   |               0.62 |      0.72 |  3.98 |       0.02 |\n",
    "    | Lars                          |               0.61 |      0.72 |  3.99 |       0.01 |\n",
    "    | LarsCV                        |               0.61 |      0.71 |  4.02 |       0.04 |\n",
    "    | SGDRegressor                  |               0.60 |      0.70 |  4.07 |       0.01 |\n",
    "    | TweedieRegressor              |               0.59 |      0.70 |  4.12 |       0.01 |\n",
    "    | GeneralizedLinearRegressor    |               0.59 |      0.70 |  4.12 |       0.01 |\n",
    "    | ElasticNet                    |               0.58 |      0.69 |  4.16 |       0.01 |\n",
    "    | Lasso                         |               0.54 |      0.66 |  4.35 |       0.02 |\n",
    "    | RANSACRegressor               |               0.53 |      0.65 |  4.41 |       0.04 |\n",
    "    | OrthogonalMatchingPursuitCV   |               0.45 |      0.59 |  4.78 |       0.02 |\n",
    "    | PassiveAggressiveRegressor    |               0.37 |      0.54 |  5.09 |       0.01 |\n",
    "    | GaussianProcessRegressor      |               0.23 |      0.43 |  5.65 |       0.03 |\n",
    "    | OrthogonalMatchingPursuit     |               0.16 |      0.38 |  5.89 |       0.01 |\n",
    "    | ExtraTreeRegressor            |               0.08 |      0.32 |  6.17 |       0.01 |\n",
    "    | DummyRegressor                |              -0.38 |     -0.02 |  7.56 |       0.01 |\n",
    "    | LassoLars                     |              -0.38 |     -0.02 |  7.56 |       0.01 |\n",
    "    | KernelRidge                   |             -11.50 |     -8.25 | 22.74 |       0.01 |\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        verbose=0,\n",
    "        ignore_warnings=True,\n",
    "        custom_metric=None,\n",
    "        predictions=False,\n",
    "        random_state=42,\n",
    "        regressors=\"all\",\n",
    "    ):\n",
    "        self.verbose = verbose\n",
    "        self.ignore_warnings = ignore_warnings\n",
    "        self.custom_metric = custom_metric\n",
    "        self.predictions = predictions\n",
    "        self.models = {}\n",
    "        self.random_state = random_state\n",
    "        self.regressors = regressors\n",
    "\n",
    "    def fit(self, X_train, X_test, y_train, y_test):\n",
    "        \"\"\"Fit Regression algorithms to X_train and y_train, predict and score on X_test, y_test.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like,\n",
    "            Training vectors, where rows is the number of samples\n",
    "            and columns is the number of features.\n",
    "        X_test : array-like,\n",
    "            Testing vectors, where rows is the number of samples\n",
    "            and columns is the number of features.\n",
    "        y_train : array-like,\n",
    "            Training vectors, where rows is the number of samples\n",
    "            and columns is the number of features.\n",
    "        y_test : array-like,\n",
    "            Testing vectors, where rows is the number of samples\n",
    "            and columns is the number of features.\n",
    "        Returns\n",
    "        -------\n",
    "        scores : Pandas DataFrame\n",
    "            Returns metrics of all the models in a Pandas DataFrame.\n",
    "        predictions : Pandas DataFrame\n",
    "            Returns predictions of all the models in a Pandas DataFrame.\n",
    "        \"\"\"\n",
    "        R2 = []\n",
    "        ADJR2 = []\n",
    "        RMSE = []\n",
    "        # WIN = []\n",
    "        names = []\n",
    "        TIME = []\n",
    "        predictions = {}\n",
    "\n",
    "        if self.custom_metric:\n",
    "            CUSTOM_METRIC = []\n",
    "\n",
    "        if isinstance(X_train, np.ndarray):\n",
    "            X_train = pd.DataFrame(X_train)\n",
    "            X_test = pd.DataFrame(X_test)\n",
    "\n",
    "        numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "        categorical_features = X_train.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "        categorical_low, categorical_high = get_card_split(\n",
    "            X_train, categorical_features\n",
    "        )\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"numeric\", numeric_transformer, numeric_features),\n",
    "                (\"categorical_low\", categorical_transformer_low, categorical_low),\n",
    "                (\"categorical_high\", categorical_transformer_high, categorical_high),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if self.regressors == \"all\":\n",
    "            self.regressors = REGRESSORS\n",
    "        else:\n",
    "            try:\n",
    "                temp_list = []\n",
    "                for regressor in self.regressors:\n",
    "                    full_name = (regressor.__name__, regressor)\n",
    "                    temp_list.append(full_name)\n",
    "                self.regressors = temp_list\n",
    "            except Exception as exception:\n",
    "                print(exception)\n",
    "                print(\"Invalid Regressor(s)\")\n",
    "\n",
    "        for name, model in tqdm(self.regressors):\n",
    "            start = time.time()\n",
    "            try:\n",
    "                if \"random_state\" in model().get_params().keys():\n",
    "                    pipe = Pipeline(\n",
    "                        steps=[\n",
    "                            (\"preprocessor\", preprocessor),\n",
    "                            (\"regressor\", model(random_state=self.random_state)),\n",
    "                        ]\n",
    "                    )\n",
    "                else:\n",
    "                    pipe = Pipeline(\n",
    "                        steps=[(\"preprocessor\", preprocessor), (\"regressor\", model())]\n",
    "                    )\n",
    "\n",
    "                pipe.fit(X_train, y_train)\n",
    "                self.models[name] = pipe\n",
    "                y_pred = pipe.predict(X_test)\n",
    "\n",
    "                r_squared = r2_score(y_test, y_pred)\n",
    "                #adj_rsquared = adjusted_rsquared(\n",
    "                    #r_squared, X_test.shape[0], X_test.shape[1]\n",
    "                #)\n",
    "                rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "                names.append(name)\n",
    "                R2.append(r_squared)\n",
    "                #ADJR2.append(adj_rsquared)\n",
    "                RMSE.append(rmse)\n",
    "                TIME.append(time.time() - start)\n",
    "\n",
    "                if self.custom_metric:\n",
    "                    custom_metric = self.custom_metric(y_test, y_pred)\n",
    "                    CUSTOM_METRIC.append(custom_metric)\n",
    "\n",
    "                if self.verbose > 0:\n",
    "                    scores_verbose = {\n",
    "                        \"Model\": name,\n",
    "                        \"R-Squared\": r_squared,\n",
    "                        #\"Adjusted R-Squared\": adj_rsquared,\n",
    "                        \"RMSE\": rmse,\n",
    "                        \"Time taken\": time.time() - start,\n",
    "                    }\n",
    "\n",
    "                    if self.custom_metric:\n",
    "                        scores_verbose[self.custom_metric.__name__] = custom_metric\n",
    "\n",
    "                    print(scores_verbose)\n",
    "                if self.predictions:\n",
    "                    predictions[name] = y_pred\n",
    "            except Exception as exception:\n",
    "                if self.ignore_warnings is False:\n",
    "                    print(name + \" model failed to execute\")\n",
    "                    print(exception)\n",
    "\n",
    "        scores = {\n",
    "            \"Model\": names,\n",
    "            #\"Adjusted R-Squared\": ADJR2,\n",
    "            \"R-Squared\": R2,\n",
    "            \"RMSE\": RMSE,\n",
    "            \"Time Taken\": TIME,\n",
    "        }\n",
    "\n",
    "        if self.custom_metric:\n",
    "            scores[self.custom_metric.__name__] = CUSTOM_METRIC\n",
    "\n",
    "        scores = pd.DataFrame(scores)\n",
    "        scores = scores.sort_values(by=\"RMSE\", ascending=True).set_index(\n",
    "            \"Model\"\n",
    "        )\n",
    "\n",
    "        if self.predictions:\n",
    "            predictions_df = pd.DataFrame.from_dict(predictions)\n",
    "        return scores, predictions_df if self.predictions is True else scores\n",
    "\n",
    "    def provide_models(self, X_train, X_test, y_train, y_test):\n",
    "        \"\"\"\n",
    "        This function returns all the model objects trained in fit function.\n",
    "        If fit is not called already, then we call fit and then return the models.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like,\n",
    "            Training vectors, where rows is the number of samples\n",
    "            and columns is the number of features.\n",
    "        X_test : array-like,\n",
    "            Testing vectors, where rows is the number of samples\n",
    "            and columns is the number of features.\n",
    "        y_train : array-like,\n",
    "            Training vectors, where rows is the number of samples\n",
    "            and columns is the number of features.\n",
    "        y_test : array-like,\n",
    "            Testing vectors, where rows is the number of samples\n",
    "            and columns is the number of features.\n",
    "        Returns\n",
    "        -------\n",
    "        models: dict-object,\n",
    "            Returns a dictionary with each model pipeline as value \n",
    "            with key as name of models.\n",
    "        \"\"\"\n",
    "        if len(self.models.keys()) == 0:\n",
    "            self.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "        return self.models\n",
    "\n",
    "\n",
    "Regression = LazyRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:03<00:00, 12.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>QuantileRegressor</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>6.58</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLarsCV</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>6.58</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoCV</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>6.58</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>6.58</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LarsCV</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>6.58</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLarsIC</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>6.58</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLars</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>6.58</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>6.58</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNetCV</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>6.58</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyRegressor</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>6.58</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BayesianRidge</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>6.58</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GammaRegressor</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>6.60</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TweedieRegressor</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>6.61</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuitCV</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>6.61</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuit</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>6.61</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoissonRegressor</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>6.64</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeCV</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>6.64</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>6.64</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>6.64</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lars</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>6.64</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransformedTargetRegressor</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>6.64</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDRegressor</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>6.64</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HuberRegressor</th>\n",
       "      <td>-0.03</td>\n",
       "      <td>6.66</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingRegressor</th>\n",
       "      <td>-0.04</td>\n",
       "      <td>6.72</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>-0.04</td>\n",
       "      <td>6.72</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVR</th>\n",
       "      <td>-0.05</td>\n",
       "      <td>6.72</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR</th>\n",
       "      <td>-0.06</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>-0.08</td>\n",
       "      <td>6.85</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>-0.09</td>\n",
       "      <td>6.86</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>-0.09</td>\n",
       "      <td>6.86</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>6.96</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>6.96</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>-0.17</td>\n",
       "      <td>7.10</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>-0.22</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>-0.23</td>\n",
       "      <td>7.29</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor</th>\n",
       "      <td>-0.23</td>\n",
       "      <td>7.29</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RANSACRegressor</th>\n",
       "      <td>-0.23</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeRegressor</th>\n",
       "      <td>-0.24</td>\n",
       "      <td>7.33</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>-0.24</td>\n",
       "      <td>7.33</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveRegressor</th>\n",
       "      <td>-0.30</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessRegressor</th>\n",
       "      <td>-0.35</td>\n",
       "      <td>7.64</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelRidge</th>\n",
       "      <td>-3.95</td>\n",
       "      <td>14.63</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               R-Squared  RMSE  Time Taken\n",
       "Model                                                     \n",
       "QuantileRegressor                  -0.00  6.58        0.83\n",
       "LassoLarsCV                        -0.00  6.58        0.02\n",
       "LassoCV                            -0.00  6.58        0.11\n",
       "Lasso                              -0.00  6.58        0.01\n",
       "LarsCV                             -0.00  6.58        0.03\n",
       "LassoLarsIC                        -0.00  6.58        0.02\n",
       "LassoLars                          -0.00  6.58        0.01\n",
       "ElasticNet                         -0.00  6.58        0.02\n",
       "ElasticNetCV                       -0.00  6.58        0.16\n",
       "DummyRegressor                     -0.00  6.58        0.02\n",
       "BayesianRidge                      -0.00  6.58        0.05\n",
       "GammaRegressor                     -0.01  6.60        0.02\n",
       "TweedieRegressor                   -0.01  6.61        0.02\n",
       "OrthogonalMatchingPursuitCV        -0.01  6.61        0.02\n",
       "OrthogonalMatchingPursuit          -0.01  6.61        0.01\n",
       "PoissonRegressor                   -0.02  6.64        0.01\n",
       "RidgeCV                            -0.02  6.64        0.01\n",
       "Ridge                              -0.02  6.64        0.01\n",
       "LinearRegression                   -0.02  6.64        0.02\n",
       "Lars                               -0.02  6.64        0.02\n",
       "TransformedTargetRegressor         -0.02  6.64        0.02\n",
       "SGDRegressor                       -0.02  6.64        0.02\n",
       "HuberRegressor                     -0.03  6.66        0.02\n",
       "HistGradientBoostingRegressor      -0.04  6.72        0.29\n",
       "LGBMRegressor                      -0.04  6.72        0.04\n",
       "NuSVR                              -0.05  6.72        0.03\n",
       "LinearSVR                          -0.06  6.77        0.02\n",
       "GradientBoostingRegressor          -0.08  6.85        0.11\n",
       "SVR                                -0.09  6.86        0.04\n",
       "MLPRegressor                       -0.09  6.86        0.49\n",
       "KNeighborsRegressor                -0.12  6.96        0.02\n",
       "AdaBoostRegressor                  -0.12  6.96        0.02\n",
       "RandomForestRegressor              -0.17  7.10        0.24\n",
       "XGBRegressor                       -0.22  7.25        0.16\n",
       "ExtraTreesRegressor                -0.23  7.29        0.19\n",
       "BaggingRegressor                   -0.23  7.29        0.04\n",
       "RANSACRegressor                    -0.23  7.30        0.18\n",
       "ExtraTreeRegressor                 -0.24  7.33        0.02\n",
       "DecisionTreeRegressor              -0.24  7.33        0.02\n",
       "PassiveAggressiveRegressor         -0.30  7.50        0.01\n",
       "GaussianProcessRegressor           -0.35  7.64        0.04\n",
       "KernelRidge                        -3.95 14.63        0.02"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LazyRegressor(verbose=0,ignore_warnings=False, custom_metric=None )\n",
    "models,predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Less RMSE for several models, lowest time at Lasso and LassoLars. I will use Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11fd67006ca27d8c3de757c93fc3ec30e6504c490ec43f275b6f9d00aa4c6782"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
